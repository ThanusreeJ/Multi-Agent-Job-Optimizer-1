# ğŸ¤– Multi-Agent Production Job Optimizer

> **AI-Powered Pharmaceutical Manufacturing Scheduler** using LangChain, LangGraph & Groq LLMs

A sophisticated multi-agent system that optimizes production job scheduling across manufacturing machines using coordinated AI agents. Built with **LangGraph orchestration**, **Groq's Llama models**, and **FastAPI + React**, this system intelligently handles complex constraints like rush orders, machine downtime, setup times, and shift patterns.

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Prerequisites](#-prerequisites)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Running the Application](#-running-the-application)
- [Usage Guide](#-usage-guide)
- [API Documentation](#-api-documentation)
- [Project Structure](#-project-structure)
- [Agent Roles](#-agent-roles)
- [How It Works](#-how-it-works)
- [Contributing](#-contributing)
- [License](#-license)

---

## âœ¨ Features

### ğŸ¯ Core Capabilities
- **Multi-Agent Coordination**: 4 specialized AI agents working together via LangGraph orchestration
- **Supervisor Intelligence**: Autonomous decision-making that selects optimal schedules using weighted KPI analysis
- **Real-time Optimization**: Handles dynamic constraints (rush orders, machine failures, downtime windows)
- **Explainable AI**: Generates executive-level explanations for scheduling decisions
- **Comparative Analysis**: Run and compare multiple scheduling strategies side-by-side

### ğŸ“Š Optimization Strategies
1. **Baseline (FCFS)**: Simple First-Come-First-Serve scheduling
2. **Batching Agent**: AI-powered setup time minimization through intelligent job grouping
3. **Bottleneck Agent**: Load balancing across machines to eliminate production bottlenecks
4. **Orchestrated Mode**: Supervisor Agent coordinates all strategies and selects the best outcome

### ğŸ” Key Metrics Tracked
- Total Tardiness (deadline adherence)
- Setup Time & Product Switches
- Machine Utilization & Load Balance
- Makespan (total production time)
- Constraint Violations
- Weighted Efficiency Score

### ğŸ¨ User Interface
- Interactive Gantt Chart visualization
- Job Allocation Tables
- KPI Dashboard with real-time metrics
- Constraint Violation Reports
- AI-generated explanations
- CSV upload/download support
- Machine failure simulation

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React + Vite)                       â”‚
â”‚  Job Input | Downtime Panel | Optimization Controls | Dashboard â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASTAPI BACKEND (Port 8000)                   â”‚
â”‚         /api/optimize/* | /api/data/* | /api/simulate/*         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ORCHESTRATOR + SUPERVISOR AGENT                     â”‚
â”‚   â€¢ Coordinates specialist agents (parallel execution)          â”‚
â”‚   â€¢ Validates schedules via Constraint Agent                    â”‚
â”‚   â€¢ Scores & ranks using weighted KPIs                          â”‚
â”‚   â€¢ Generates LLM explanations (Groq llama-3.3-70b)            â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚                â”‚
     â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BASELINEâ”‚    â”‚ BATCHING â”‚    â”‚ BOTTLENECK  â”‚
â”‚  Agent  â”‚    â”‚  Agent   â”‚    â”‚   Agent     â”‚
â”‚ (Rule)  â”‚    â”‚  (LLM)   â”‚    â”‚   (LLM)     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
     â”‚              â”‚                  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  CONSTRAINT    â”‚
            â”‚     AGENT      â”‚
            â”‚  (Validator)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Components:**
- **Orchestrator**: Manages workflow, delegates tasks, consolidates results
- **Supervisor Logic**: Integrated decision-making and schedule selection
- **Specialist Agents**: Batching (setup optimization), Bottleneck (load balancing), Baseline (FCFS)
- **Constraint Agent**: Validates against shift times, downtimes, priorities, machine compatibility
- **KPI Calculator**: Computes tardiness, setup time, balance variance, weighted scores

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Framework**: FastAPI (Python 3.10+)
- **AI Orchestration**: LangChain + LangGraph
- **LLM Provider**: Groq API (llama-3.3-70b-versatile, llama-3.1-8b-instant)
- **Validation**: Pydantic v2
- **Tracing**: LangSmith (optional observability)

### Frontend
- **Framework**: React 19 + Vite
- **UI Components**: Custom components with Lucide icons
- **Charts**: Recharts for visualizations
- **HTTP Client**: Axios
- **Styling**: CSS3 with CSS Variables (dark/light theme support)

### Development Tools
- **Package Manager**: npm (frontend), pip (backend)
- **Hot Reload**: Uvicorn (backend), Vite (frontend)
- **API Testing**: FastAPI Swagger UI at `/docs`

---

## ğŸ“¦ Prerequisites

Ensure you have the following installed:

- **Python**: 3.10 or higher
- **Node.js**: 18.x or higher
- **npm**: 9.x or higher
- **Groq API Key**: Sign up at [https://console.groq.com](https://console.groq.com)
- **LangSmith API Key** (optional): For tracing - [https://smith.langchain.com](https://smith.langchain.com)

---

## ğŸš€ Installation

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/multi-agent-job-optimizer.git
cd multi-agent-job-optimizer
```

### 2. Backend Setup

#### Navigate to backend directory
```bash
cd backend
```

#### Create virtual environment (recommended)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

#### Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Frontend Setup

#### Navigate to frontend directory
```bash
cd ../frontend
```

#### Install dependencies
```bash
npm install
```

---

## âš™ï¸ Configuration

### Backend Configuration

Create a `.env` file in the `backend/` directory:

```env
# REQUIRED: Groq API Key
GROQ_API_KEY=your_groq_api_key_here

# OPTIONAL: LangSmith Tracing (for debugging/monitoring)
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=multi-agent-job-optimizer
LANGCHAIN_TRACING_V2=true

# MODEL CONFIGURATION (already set in config.py, but can override)
# MODEL_NAME=llama-3.3-70b-versatile
# FAST_MODEL_NAME=llama-3.1-8b-instant
```

**Getting API Keys:**
1. **Groq API Key**: 
   - Sign up at [https://console.groq.com](https://console.groq.com)
   - Navigate to API Keys section
   - Create new key and copy it

2. **LangSmith API Key** (optional):
   - Sign up at [https://smith.langchain.com](https://smith.langchain.com)
   - Create new API key in settings

### Frontend Configuration

The frontend is pre-configured to connect to `http://localhost:8000/api`. If you need to change this:

Edit `frontend/src/services/api.js`:
```javascript
const API_BASE_URL = 'http://localhost:8000/api';
```

---

## ğŸ® Running the Application

### Method 1: Manual Start (Recommended for Development)

#### Terminal 1 - Start Backend
```bash
cd backend
python main.py
```
Expected output:
```
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [xxxxx] using StatReload
```

#### Terminal 2 - Start Frontend
```bash
cd frontend
npm run dev
```
Expected output:
```
VITE v5.x.x  ready in xxx ms
âœ  Local:   http://localhost:5173/
```

### Method 2: Using PowerShell (Windows)

```powershell
# Start Backend (in one terminal)
Set-Location "path\to\backend"
python main.py

# Start Frontend (in another terminal)
Set-Location "path\to\frontend"
npm run dev
```

### Access the Application

Once both servers are running:
- **Frontend UI**: http://localhost:5173 (or 5174 if 5173 is occupied)
- **Backend API Docs**: http://localhost:8000/docs (Swagger UI)
- **API Root**: http://localhost:8000/api

---

## ğŸ“– Usage Guide

### Step 1: Generate or Upload Data

#### Option A: Generate Random Data
1. Click **"Generate Random Data"** button
2. Adjust parameters (job count, rush probability, downtime count)
3. System generates sample pharmaceutical production jobs

#### Option B: Upload CSV Files
1. Prepare CSV files following the format in `sample_jobs.csv` and `sample_downtime.csv`
2. Click **"Upload Jobs CSV"** 
3. Click **"Upload Downtime CSV"** (optional)

**Job CSV Format:**
```csv
job_id,product_type,machine_options,processing_time,due_time,priority
J001,Tablet_A,"M1,M2",45,14:30,Normal
J002,Capsule_B,"M2,M3",60,12:00,Rush
```

**Downtime CSV Format:**
```csv
machine_id,start_time,end_time,reason
M1,10:00,11:00,Planned Maintenance
M3,14:00,15:30,Calibration
```

### Step 2: Run Optimization

Click one of the optimization strategies:

1. **Baseline (FCFS)**: Quick, rule-based scheduling
2. **Batching (AI)**: LLM-optimized setup reduction
3. **Bottleneck (AI)**: LLM-optimized load balancing
4. **Orchestrated**: Supervisor selects best strategy automatically
5. **Compare All**: Runs all 4 and shows side-by-side comparison

### Step 3: Review Results

The dashboard displays:
- **Gantt Chart**: Visual timeline of job assignments per machine
- **Job Allocation Table**: Detailed schedule with start/end times
- **KPI Summary**: Metrics cards showing performance indicators
- **Explanation Panel**: AI-generated reasoning for decisions
- **Violation Report**: Any constraint breaches (should be zero for valid schedules)

### Step 4: Simulate Failures (Optional)

1. Click **"Simulate Failure"** button
2. Select a machine and downtime window
3. System re-optimizes schedule around the failure
4. Compare before/after metrics

---

## ğŸ”Œ API Documentation

### Data Endpoints

#### Generate Random Data
```http
POST /api/data/generate-random?job_count=20&rush_prob=0.2&downtime_count=0&machine_count=4
```

#### Upload Jobs CSV
```http
POST /api/data/upload-jobs
Content-Type: multipart/form-data
Body: file=jobs.csv
```

#### Upload Downtime CSV
```http
POST /api/data/upload-downtime
Content-Type: multipart/form-data
Body: file=downtime.csv
```

### Optimization Endpoints

#### Run Baseline Optimization
```http
POST /api/optimize/baseline
Content-Type: application/json

{
  "jobs": [...],
  "downtimes": [...],
  "shift": {"start_time": "08:00", "end_time": "16:00"}
}
```

#### Run Batching Optimization
```http
POST /api/optimize/batching
```

#### Run Bottleneck Optimization
```http
POST /api/optimize/bottleneck
```

#### Run Orchestrated (Supervisor Selection)
```http
POST /api/optimize/orchestrated
```

#### Compare All Strategies
```http
POST /api/optimize/compare-all
```

**Response Format (AgentResult):**
```json
{
  "agent_name": "Batching Agent",
  "schedules": {
    "M1": [{"job_id": "J001", "start_time": "08:00", "end_time": "08:45", ...}],
    "M2": [...]
  },
  "kpis": {
    "total_tardiness": 15,
    "total_setup_time": 30,
    "product_switches": 3,
    "score": 87.5,
    ...
  },
  "explanation": "As the Supervisor Agent, I have selected...",
  "violations": []
}
```

### Simulation Endpoints

#### Simulate Machine Failure
```http
POST /api/simulate/machine-failure?machine_id=M1
```

---

## ğŸ“ Project Structure

```
Multi-agent-main/
â”‚
â”œâ”€â”€ backend/                          # FastAPI Backend
â”‚   â”œâ”€â”€ agents/                       # Multi-agent system
â”‚   â”‚   â”œâ”€â”€ base_agent.py            # Abstract base class
â”‚   â”‚   â”œâ”€â”€ baseline_agent.py        # FCFS scheduler
â”‚   â”‚   â”œâ”€â”€ batching_agent.py        # Setup optimization (LLM)
â”‚   â”‚   â”œâ”€â”€ bottleneck_agent.py      # Load balancing (LLM)
â”‚   â”‚   â”œâ”€â”€ constraint_agent.py      # Validation logic
â”‚   â”‚   â””â”€â”€ orchestrator.py          # Supervisor + Coordination
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                       # Data models & generators
â”‚   â”‚   â”œâ”€â”€ schemas.py               # Pydantic models
â”‚   â”‚   â”œâ”€â”€ job.py                   # Job entity
â”‚   â”‚   â”œâ”€â”€ machine.py               # Machine entity
â”‚   â”‚   â””â”€â”€ data_generator.py       # Random data creation
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                       # API endpoints
â”‚   â”‚   â”œâ”€â”€ data_routes.py           # Data upload/generation
â”‚   â”‚   â”œâ”€â”€ optimization_routes.py   # Agent execution
â”‚   â”‚   â””â”€â”€ simulation_routes.py     # Failure simulation
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                        # Helper modules
â”‚   â”‚   â”œâ”€â”€ kpi_calculator.py        # Metrics computation
â”‚   â”‚   â”œâ”€â”€ csv_handler.py           # CSV parsing
â”‚   â”‚   â””â”€â”€ baseline_scheduler.py    # FCFS implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py                     # Settings & environment
â”‚   â”œâ”€â”€ main.py                       # FastAPI app entry
â”‚   â”œâ”€â”€ requirements.txt              # Python dependencies
â”‚   â””â”€â”€ .env                          # API keys (create this)
â”‚
â”œâ”€â”€ frontend/                         # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/              # UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ control/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ OptimizationPanel.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ JobInputPanel.jsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ DowntimePanel.jsx
â”‚   â”‚   â”‚   â””â”€â”€ output/
â”‚   â”‚   â”‚       â”œâ”€â”€ GanttChart.jsx
â”‚   â”‚   â”‚       â”œâ”€â”€ KPISummary.jsx
â”‚   â”‚   â”‚       â”œâ”€â”€ ExplanationPanel.jsx
â”‚   â”‚   â”‚       â””â”€â”€ ComparisonTable.jsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx        # Main application
â”‚   â”‚   â”‚   â””â”€â”€ ModeSelection.jsx    # Landing page
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js               # Axios API client
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ App.jsx                  # Root component
â”‚   â”‚   â””â”€â”€ main.jsx                 # Entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ package.json                  # npm dependencies
â”‚   â””â”€â”€ vite.config.js               # Vite configuration
â”‚
â”œâ”€â”€ agents-architecture.md            # Architecture documentation
â”œâ”€â”€ concept-note.md                   # POC design document
â”œâ”€â”€ sample_jobs.csv                   # Example job data
â”œâ”€â”€ sample_downtime.csv              # Example downtime data
â””â”€â”€ README.md                         # This file
```

---

## ğŸ¤– Agent Roles

### 1. Supervisor Agent (Embedded in Orchestrator)
**Model**: Groq llama-3.3-70b-versatile  
**Temperature**: 0.2 (low for consistent decisions)

**Responsibilities:**
- Coordinates all specialist agents via parallel execution
- Validates candidate schedules using Constraint Agent
- Scores schedules using weighted KPI formula:
  ```
  final_score = kpi_score - (violations Ã— 100)
  ```
- Selects best schedule (prioritizes zero violations)
- Generates executive-level explanations via LLM prompt

**Decision Criteria:**
1. âœ… Zero constraint violations (mandatory)
2. âœ… Minimum total tardiness (deadline adherence)
3. âœ… Balanced machine utilization
4. âœ… Fewer setup transitions

### 2. Batching & Setup Minimization Agent
**Model**: Groq llama-3.3-70b-versatile  
**Temperature**: 0.3

**Strategy:**
- Groups jobs by `product_type` to minimize changeovers
- Reduces setup time penalties (10 min per product switch)
- Uses LLM to optimize batching sequence

### 3. Bottleneck Relief Agent
**Model**: Groq llama-3.1-8b-instant (faster)  
**Temperature**: 0.4

**Strategy:**
- Detects machines with excessive load
- Redistributes jobs to underutilized machines
- Balances load variance across all machines

### 4. Baseline Agent (FCFS)
**Model**: Rule-based (no LLM)

**Strategy:**
- Simple First-Come-First-Serve scheduling
- Assigns jobs to first available compatible machine
- Provides baseline for comparison

### 5. Constraint Agent (Validator)
**Model**: Rule-based (no LLM)

**Validation Rules:**
- âŒ Jobs outside shift hours (08:00-16:00)
- âŒ Jobs during machine downtime windows
- âŒ Jobs assigned to incompatible machines
- âŒ Rush jobs not prioritized
- âŒ Invalid time overlaps

---

## ğŸ”„ How It Works

### Optimization Flow (Orchestrated Mode)

```
1. User Input
   â†“
2. Frontend sends OptimizationRequest â†’ FastAPI
   â†“
3. Orchestrator receives request
   â†“
4. Parallel Execution (asyncio.gather):
   â”œâ”€â†’ Baseline Agent â†’ Schedule A
   â”œâ”€â†’ Batching Agent (LLM) â†’ Schedule B
   â””â”€â†’ Bottleneck Agent (LLM) â†’ Schedule C
   â†“
5. Each schedule â†’ KPI Calculator â†’ Metrics
   â†“
6. Orchestrator â†’ Constraint Agent â†’ Validate A, B, C
   â†“
7. Supervisor Scoring:
   For each candidate:
     violation_penalty = violations Ã— 100
     final_score = kpi_score - violation_penalty
   â†“
8. Select highest scoring candidate
   â†“
9. Generate LLM Explanation:
   "You are Supervisor Agent for Pharmaceutical Production..."
   â†“
10. Return AgentResult â†’ Frontend
    â†“
11. Render Gantt Chart + KPIs + Explanation
```

### KPI Calculation Formula

```python
# Setup Time: 10 minutes per product type switch
total_setup_time = product_switches Ã— 10

# Tardiness: Minutes late beyond due_time
total_tardiness = sum(max(0, end_time - due_time))

# Load Balance: Variance in machine utilization
variance = Î£(load - mean_load)Â² / machine_count

# Weighted Score (higher is better):
completion_bonus = (scheduled_jobs / total_jobs) Ã— 40
tardiness_penalty = min(total_tardiness Ã— 0.3, 30)
setup_penalty = min(total_setup_time Ã— 0.2, 20)
balance_penalty = min(variance Ã— 0.01, 10)

score = completion_bonus + 60 - penalties
```

---

## ğŸ§ª Testing

### Run Backend Tests
```bash
cd backend
python test_complete_system.py
```

### Manual API Testing
1. Start backend server
2. Navigate to http://localhost:8000/docs
3. Use Swagger UI to test endpoints interactively

### Frontend Testing
```bash
cd frontend
npm run lint
```

---

## ğŸ› Troubleshooting

### Backend Issues

**Issue**: `ModuleNotFoundError: No module named 'langchain'`
```bash
# Solution: Install dependencies
pip install -r requirements.txt
```

**Issue**: `groq.error.AuthenticationError`
```bash
# Solution: Check .env file has valid GROQ_API_KEY
# Verify key at https://console.groq.com
```

**Issue**: Port 8000 already in use
```bash
# Solution: Kill existing process or change port in main.py
uvicorn.run("main:app", host="0.0.0.0", port=8001, reload=True)
```

### Frontend Issues

**Issue**: `Network Error` when calling API
```bash
# Solution 1: Ensure backend is running on port 8000
# Solution 2: Check CORS configuration in backend/main.py
# Solution 3: Verify API_BASE_URL in frontend/src/services/api.js
```

**Issue**: Port 5173 already in use
```bash
# The frontend will automatically try port 5174
# Or kill existing Vite process
```

### LangSmith Tracing Issues

If you don't want tracing:
```env
# In .env file, set:
LANGCHAIN_TRACING_V2=false
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 for Python code
- Use ESLint for JavaScript/React code
- Add docstrings to new functions/classes
- Update README.md for new features

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **LangChain Team** for the amazing orchestration framework
- **Groq** for lightning-fast LLM inference
- **FastAPI** for the excellent web framework
- **React Team** for the UI library

---

## ğŸ“ Support

For issues, questions, or feature requests:
- Open an [Issue](https://github.com/yourusername/multi-agent-job-optimizer/issues)
- Email: your.email@example.com
- Documentation: See `agents-architecture.md` and `concept-note.md`

---

## ğŸš€ Future Enhancements

- [ ] RAG integration for historical scheduling patterns
- [ ] Real-time WebSocket updates
- [ ] Database persistence (PostgreSQL/MongoDB)
- [ ] Multi-shift support (24/7 operations)
- [ ] Advanced visualizations (3D Gantt, heatmaps)
- [ ] Export to PDF/Excel reports
- [ ] User authentication & role-based access
- [ ] Mobile responsive design
- [ ] Docker containerization
- [ ] Kubernetes deployment manifests

---

**Built with â¤ï¸ for Pharmaceutical Manufacturing Excellence**
